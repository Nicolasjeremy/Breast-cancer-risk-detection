{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AakuBP_-pf_Y"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from Bio import SeqIO # pip install BioPython\n",
        "import re\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, TimeDistributed, Dropout, Conv1D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tcn import TCN  # pip install keras-tcn\n",
        "from sklearn.model_selection import train_test_split\n",
        "import gdown # pip install gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Tf5hTkiLgnb",
        "outputId": "d6a7bfbe-e887-410d-8fe6-0e49a01c34fb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=11I3wA5XpIBwIKSWJAqBuLR490G-OxbwY\n",
            "To: C:\\data\\Cosmic_Genes_v102_GRCh38.fasta\n",
            "100%|█████████████████████████████████████████████████████████████████████████████| 92.8M/92.8M [00:24<00:00, 3.73MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1_fGHi4ifXKBiMOZyUc3kPqk3QqQGd8xu\n",
            "To: C:\\data\\CellLinesProject_GenomeScreensMutant_Tsv_v102_GRCh38\n",
            "100%|██████████████████████████████████████████████████████████████████████████████| 29.7k/29.7k [00:00<00:00, 867kB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1YKFPQbGMC9kiOG4lTNjteNu1fdrWqVDy\n",
            "To: C:\\data\\Cosmic_GenomeScreensMutant_Tsv_v102_GRCh38\n",
            "100%|█████████████████████████████████████████████████████████████████████████████| 65.4k/65.4k [00:00<00:00, 1.07MB/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'data/Cosmic_GenomeScreensMutant_Tsv_v102_GRCh38'"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# os.makedirs(\"data\", exist_ok=True)\n",
        "\n",
        "# # 1. DNA Sequence\n",
        "# fasta_file_id = \"11I3wA5XpIBwIKSWJAqBuLR490G-OxbwY\"\n",
        "# fasta_output = \"data/Cosmic_Genes_v102_GRCh38.fasta\"\n",
        "# gdown.download(f\"https://drive.google.com/uc?id={fasta_file_id}\", fasta_output, quiet=False)\n",
        "\n",
        "# # 2. BRCA1\n",
        "# brca1_file_id = \"1_fGHi4ifXKBiMOZyUc3kPqk3QqQGd8xu\"\n",
        "# brca1_output = \"data/CellLinesProject_GenomeScreensMutant_Tsv_v102_GRCh38\"\n",
        "# gdown.download(f\"https://drive.google.com/uc?id={brca1_file_id}\", brca1_output, quiet=False)\n",
        "\n",
        "# # 3. BRCA2\n",
        "# brca2_file_id = \"1YKFPQbGMC9kiOG4lTNjteNu1fdrWqVDy\"\n",
        "# brca2_output = \"data/Cosmic_GenomeScreensMutant_Tsv_v102_GRCh38\"\n",
        "# gdown.download(f\"https://drive.google.com/uc?id={brca2_file_id}\", brca2_output, quiet=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "h_vm3JrNqwwX"
      },
      "outputs": [],
      "source": [
        "def parse_fasta_header(header):\n",
        "    parts = header.split()\n",
        "    transcript_id = parts[1]  # ENST00000641515.2\n",
        "    chrom_info = parts[2]     # '1:65419-71585(+)'\n",
        "    chrom, rest = chrom_info.split(\":\")\n",
        "    start_end = re.match(r'(\\d+-\\d+)', rest).group(1)\n",
        "    start, end = map(int, start_end.split(\"-\"))\n",
        "    strand = rest[-2]  # karakter sebelum ')'\n",
        "    return transcript_id, chrom, start, end, strand"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "KZcdrs6hq0_4"
      },
      "outputs": [],
      "source": [
        "def load_fasta_sequences_with_pos(fasta_path):\n",
        "    seq_dict = {}\n",
        "    pos_dict = {}\n",
        "    for record in SeqIO.parse(fasta_path, \"fasta\"):\n",
        "        transcript_id, chrom, start, end, strand = parse_fasta_header(record.description)\n",
        "        seq_dict[transcript_id] = str(record.seq)\n",
        "        pos_dict[transcript_id] = (start, end, strand)\n",
        "    return seq_dict, pos_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "MyI_2f4e6F5f"
      },
      "outputs": [],
      "source": [
        "def load_mutation_data(cellline_path, cosmic_path):\n",
        "    df1 = pd.read_csv(cellline_path, sep='\\t')\n",
        "    df2 = pd.read_csv(cosmic_path, sep='\\t')\n",
        "    df = pd.concat([df1, df2], ignore_index=True)\n",
        "    df = df.dropna(subset=[\"TRANSCRIPT_ACCESSION\", \"GENOME_START\"])\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "s-DD9BPXq3eo"
      },
      "outputs": [],
      "source": [
        "def label_mutations_on_seq(mutations_df, seq_pos_dict, sequences):\n",
        "    X = []\n",
        "    y = []\n",
        "\n",
        "    for transcript_id in mutations_df['TRANSCRIPT_ACCESSION'].unique():\n",
        "        if transcript_id not in sequences or transcript_id not in seq_pos_dict:\n",
        "            continue\n",
        "        seq = sequences[transcript_id]\n",
        "        seq_len = len(seq)\n",
        "        start_genome, end_genome, strand = seq_pos_dict[transcript_id]\n",
        "\n",
        "        labels = np.zeros(seq_len, dtype=int)\n",
        "        muts = mutations_df[mutations_df['TRANSCRIPT_ACCESSION'] == transcript_id]\n",
        "\n",
        "        for _, mut in muts.iterrows():\n",
        "            mut_pos_genome = mut['GENOME_START']\n",
        "\n",
        "            pos_in_seq = mut_pos_genome - start_genome\n",
        "            if strand == '-':\n",
        "                pos_in_seq = (end_genome - mut_pos_genome)\n",
        "\n",
        "            if 0 <= pos_in_seq < seq_len:\n",
        "                labels[pos_in_seq] = 1\n",
        "\n",
        "        X.append(seq)\n",
        "        y.append(labels)\n",
        "\n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Jr2Glfemq4lL"
      },
      "outputs": [],
      "source": [
        "def sequence_to_integer(seq):\n",
        "    mapping = {'A':0, 'C':1, 'G':2, 'T':3, 'N':4}\n",
        "    return np.array([mapping.get(base.upper(), 4) for base in seq])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "hBq78Selq6Fp"
      },
      "outputs": [],
      "source": [
        "def encode_and_pad_sequences(X_seqs, y_labels, max_len=None):\n",
        "    X_int = [sequence_to_integer(seq) for seq in X_seqs]\n",
        "\n",
        "    if max_len is None:\n",
        "        max_len = max(len(s) for s in X_int)\n",
        "\n",
        "    X_pad = pad_sequences(X_int, maxlen=max_len, padding='post', value=0)\n",
        "    y_pad = pad_sequences(y_labels, maxlen=max_len, padding='post', value=0)\n",
        "\n",
        "    return np.array(X_pad), np.array(y_pad), max_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "VukGZ35LtCDa"
      },
      "outputs": [],
      "source": [
        "def build_tcn_model(vocab_size, embedding_dim, max_len, num_classes=2):\n",
        "    model = Sequential([\n",
        "        Embedding(vocab_size, embedding_dim),\n",
        "        TCN(nb_filters=64, kernel_size=3, dilations=[1, 2, 4, 8], padding='causal', use_skip_connections=True, return_sequences=True),\n",
        "        Dropout(0.3),\n",
        "        TimeDistributed(Dense(num_classes, activation='softmax'))\n",
        "    ])\n",
        "    model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(0.001), metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "8WCUYOOjq9MG"
      },
      "outputs": [],
      "source": [
        "def build_1dcnn_model(vocab_size, embedding_dim, max_len, num_classes=2):\n",
        "    model = Sequential([\n",
        "        Embedding(vocab_size, embedding_dim),\n",
        "        Conv1D(64, kernel_size=5, activation='relu', padding='same'),\n",
        "        Dropout(0.3),\n",
        "        Conv1D(128, kernel_size=5, activation='relu', padding='same'),\n",
        "        Dropout(0.3),\n",
        "        Conv1D(num_classes, kernel_size=1, activation='softmax', padding='same'),\n",
        "    ])\n",
        "    model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(0.001), metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "8k4YEI8qrULZ"
      },
      "outputs": [],
      "source": [
        "def build_bilstm_model(vocab_size, embedding_dim, max_len, num_classes=2):\n",
        "    model = Sequential([\n",
        "        Embedding(vocab_size, embedding_dim),\n",
        "        Bidirectional(LSTM(64, return_sequences=True)),\n",
        "        Dropout(0.3),\n",
        "        Dense(num_classes, activation='softmax'),\n",
        "    ])\n",
        "    model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(0.001), metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "wdnI-sQzsNwo"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    fasta_path = fasta_output\n",
        "    brca1_path = brca1_output\n",
        "    brca2_path = brca2_output\n",
        "\n",
        "    print(\"Loading fasta sequences...\")\n",
        "    sequences, seq_pos_dict = load_fasta_sequences_with_pos(fasta_path)\n",
        "    print(f\"Loaded {len(sequences)} sequences.\")\n",
        "\n",
        "    print(\"Loading mutation data...\")\n",
        "    mutations_df = load_mutation_data(brca1_path, brca2_path)\n",
        "    print(f\"Loaded {len(mutations_df)} mutation records.\")\n",
        "\n",
        "    print(\"Labeling mutations on sequences...\")\n",
        "    X_seqs, y_labels = label_mutations_on_seq(mutations_df, seq_pos_dict, sequences)\n",
        "    print(f\"Prepared {len(X_seqs)} sequences with labels.\")\n",
        "\n",
        "    print(\"Encoding and padding sequences...\")\n",
        "    X_pad, y_pad, max_len = encode_and_pad_sequences(X_seqs, y_labels)\n",
        "    print(f\"Dataset shape X: {X_pad.shape}, y: {y_pad.shape}\")\n",
        "\n",
        "    print(\"Splitting dataset into train/test (50/50)...\")\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_pad, y_pad, test_size=0.5, random_state=42)\n",
        "\n",
        "    vocab_size = 5  # A,T,G,C,N\n",
        "    embedding_dim = 8\n",
        "    num_classes = 2\n",
        "\n",
        "    print(\"Building TCN model...\")\n",
        "    tcn_model = build_tcn_model(vocab_size, embedding_dim, max_len, num_classes)\n",
        "    tcn_model.summary()\n",
        "    tcn_model.fit(X_train, y_train, validation_split=0.2, epochs=5, batch_size=32)\n",
        "\n",
        "    print(\"Building 1D-CNN model...\")\n",
        "    cnn_model = build_1dcnn_model(vocab_size, embedding_dim, max_len, num_classes)\n",
        "    cnn_model.summary()\n",
        "    cnn_model.fit(X_train, y_train, validation_split=0.2, epochs=5, batch_size=32)\n",
        "\n",
        "    print(\"Building BiLSTM model...\")\n",
        "    bilstm_model = build_bilstm_model(vocab_size, embedding_dim, max_len, num_classes)\n",
        "    bilstm_model.summary()\n",
        "    bilstm_model.fit(X_train, y_train, validation_split=0.2, epochs=5, batch_size=32)\n",
        "\n",
        "    print(\"Evaluating models on test set...\")\n",
        "    print(\"TCN:\", tcn_model.evaluate(X_test, y_test))\n",
        "    print(\"1D-CNN:\", cnn_model.evaluate(X_test, y_test))\n",
        "    print(\"BiLSTM:\", bilstm_model.evaluate(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kT6xxQLsKC6",
        "outputId": "052f895d-862a-4ac6-8ecb-32639c958c4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading fasta sequences...\n",
            "Loaded 56474 sequences.\n",
            "Loading mutation data...\n",
            "Loaded 300 mutation records.\n",
            "Labeling mutations on sequences...\n",
            "Prepared 12 sequences with labels.\n",
            "Encoding and padding sequences...\n",
            "Dataset shape X: (12, 10257), y: (12, 10257)\n",
            "Splitting dataset into train/test (50/50)...\n",
            "Building TCN model...\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_6 (Embedding)     (None, None, 8)           40        \n",
            "                                                                 \n",
            " tcn_2 (TCN)                 (None, None, 64)          88640     \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, None, 64)          0         \n",
            "                                                                 \n",
            " time_distributed_2 (TimeDi  (None, None, 2)           130       \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 88810 (346.91 KB)\n",
            "Trainable params: 88810 (346.91 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5915 - accuracy: 0.8491 - val_loss: 0.4129 - val_accuracy: 1.0000\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - 0s 241ms/step - loss: 0.4132 - accuracy: 0.9965 - val_loss: 0.2475 - val_accuracy: 1.0000\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - 0s 246ms/step - loss: 0.2530 - accuracy: 0.9997 - val_loss: 0.1104 - val_accuracy: 1.0000\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - 0s 450ms/step - loss: 0.1211 - accuracy: 0.9998 - val_loss: 0.0345 - val_accuracy: 1.0000\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - 0s 245ms/step - loss: 0.0436 - accuracy: 0.9998 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
            "Building 1D-CNN model...\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_7 (Embedding)     (None, None, 8)           40        \n",
            "                                                                 \n",
            " conv1d_6 (Conv1D)           (None, None, 64)          2624      \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, None, 64)          0         \n",
            "                                                                 \n",
            " conv1d_7 (Conv1D)           (None, None, 128)         41088     \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, None, 128)         0         \n",
            "                                                                 \n",
            " conv1d_8 (Conv1D)           (None, None, 2)           258       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 44010 (171.91 KB)\n",
            "Trainable params: 44010 (171.91 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6940 - accuracy: 0.4306 - val_loss: 0.6799 - val_accuracy: 1.0000\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 0.6801 - accuracy: 0.9973 - val_loss: 0.6659 - val_accuracy: 1.0000\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 0.6661 - accuracy: 0.9998 - val_loss: 0.6505 - val_accuracy: 1.0000\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 0.6508 - accuracy: 0.9998 - val_loss: 0.6333 - val_accuracy: 1.0000\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 0.6336 - accuracy: 0.9998 - val_loss: 0.6135 - val_accuracy: 1.0000\n",
            "Building BiLSTM model...\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_8 (Embedding)     (None, None, 8)           40        \n",
            "                                                                 \n",
            " bidirectional_2 (Bidirecti  (None, None, 128)         37376     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, None, 128)         0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, None, 2)           258       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 37674 (147.16 KB)\n",
            "Trainable params: 37674 (147.16 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - 9s 9s/step - loss: 0.6989 - accuracy: 0.1600 - val_loss: 0.6816 - val_accuracy: 1.0000\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6822 - accuracy: 0.9684 - val_loss: 0.6649 - val_accuracy: 1.0000\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.6661 - accuracy: 0.9998 - val_loss: 0.6483 - val_accuracy: 1.0000\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.6501 - accuracy: 0.9998 - val_loss: 0.6310 - val_accuracy: 1.0000\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.6334 - accuracy: 0.9998 - val_loss: 0.6126 - val_accuracy: 1.0000\n",
            "Evaluating models on test set...\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.0082 - accuracy: 0.9999\n",
            "TCN: [0.008235831744968891, 0.9998537302017212]\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6137 - accuracy: 0.9999\n",
            "1D-CNN: [0.6137027144432068, 0.9998537302017212]\n",
            "1/1 [==============================] - 0s 311ms/step - loss: 0.6143 - accuracy: 0.9999\n",
            "BiLSTM: [0.6143200397491455, 0.9998537302017212]\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
